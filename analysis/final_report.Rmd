---
title: "Homework 1 Report"
author: "Danlu Zhang"
output: pdf_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(knitr)
knitr::opts_chunk$set(tidy = FALSE)
```

### Problem 1.1 ADEMP Structure 


* I will run 18 simulation scenarios.
* Estimand is $\beta_{treatment}$
* Wald confidence intervals, nonparametric boostrap percentile intervals and nonparametric bootstrap t intervals are being compared.
* Performance measures include bias, empirical standard error, and coverage.


### Problem 1.2 nSim 

Based on desired coverage of 95\% with Monte Carlo error of no more than 1\%, 475 simulations should be performed for each simulation scenario.


### Problem 1.3 Implementation 

I attached the contents of readme here.

1. **source folder** contains R functions used in the analysis:
    - 01_simulate_data.R: Simulates the dataset.
    - 02_apply_method.R: Applies linear regression to the simulated data.
    - 03_extract_estimates.R: Extracts estimates and calculates Wald confidence intervals.
    - 04_nonparametric_boot_percentile_ci.R: Computes bootstrap percentile confidence intervals.
    - 05_nonparametric_boot_t_ci.R: Computes bootstrap t-quantile confidence intervals.

2. **simulation folder** contains the script that runs the simulation using the functions from the source Folder:
   - run_simulation.R: This script calls the functions in the Source Folder to perform the simulation.

3. **data folder** stores the simulation results by scenario. The results generated by run_simulation.R are saved here.

4. **analysis folder** contains code for exploring the simulation results and generating the final report:
   - exploratory_analysis.R: Scripts for exploratory analysis of the simulation results, generating tables and figures.
   - final_report.Rmd: Code for generating final report.

5. **results folder** stores the tables and figures generated from the exploratory analysis. These files are used in the final report.

### Problem 1.4 Results summary

```{r, echo = F, out.width="60%", fig.cap="Bias of estimated beta under varying true beta values, random error distributions, and sample sizes.", fig.align="center"}
include_graphics(here::here("results","figure_for_bias.png"))
```

```{r, echo = F, out.width="70%", fig.align="center", fig.cap="Coverage based on Wald confidence intervals, nonparametric bootstrap percentile intervals, and nonparametric bootstrap t intervals under varying true beta values, random error distributions, and sample sizes. Black dashed line indicates 0.95 coverage."}

include_graphics(here::here("results","figure_for_coverage.png"))

```


```{r, echo = F, out.width="70%", fig.align="center", fig.cap="Distribution of the standard error of estimated beta under varying true beta values, random error distributions, and sample sizes."}

include_graphics(here::here("results","figure_for_se.png"))

```

Table 1. Computation time in seconds of different interval calculation methods.

| Computation Time (second) |                     Method                  |
|---------------------------|---------------------------------------------|
|          0.011            |           Wald confidence interval          |
|          0.147            | Nonparametric bootstrap percentile interval |
|          8.882            |     Nonparametric bootstrap t interval      |




### Problem 1.5 Discussion

Comparing bias of $\hat{\beta}$, smaller bias is associated with larger sample size in most cases. However, in two specific scenarios - $\beta=0.5$ with $\epsilon_i \sim logNormal(0,log(2))$ and $\beta=2$ with $\epsilon_i \sim N(0,2)$ â€”the smallest bias is observed with a sample size of 10. The coverage of Wald confidence intervals and nonparametric bootstrap t intervals remains consistently around 0.95 across all 18 scenarios. Within each scenario, the coverage of Wald confidence intervals and nonparametric bootstrap percentile intervals increases with sample size, but this trend is not observed for bootstrap t intervals. As sample size increases, standard errors become more concentrated around lower values, indicating improved estimation precision. Standard errors are generally more spread out under the lognormal error distribution compared to the normal error distribution. Among the different methods for constructing confidence intervals, the Wald confidence interval requires the least computation time, while the nonparametric bootstrap t interval is the most computationally intensive.

- How do the different methods for constructing confidence intervals compare in terms of computation time?

Wald confidence intervals take least computation time (around 0.011 seconds on average) while nonparametric bootstrap t interval take 8.882 seconds on average, which is about 800 times than Wald confidence interval. Nonparametric bootstrap percentile interval take 0.147 seconds on average.

- Which method(s) for constructing confidence intervals provide the best coverage when $\epsilon_i \sim N(0, 2)$?

Wald confidence intervals provide the best coverage.

- Which method(s) for constructing confidence intervals provide the best coverage when $\epsilon_i \sim logNormal(0, \log (2))$?

Wald confidence intervals provide the best coverage. One potential explanation is that I only ran 120 iterations to calculate the bootstrap percentile intervals, and based on that, I conducted 60 iterations to compute the t quantile. Both of these loop iterations may be too few to yield reliable results.


Git repo: https://github.com/Danlu233/BIOS731_HW1